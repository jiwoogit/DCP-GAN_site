<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="keywords" content="DCP, DCP-GAN, DCPGAN, diversity-aware channel pruning, diversity channel pruning, diversity">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="IYymxWwPaxtVlFH8FLH35zgFoZlGsJb2dLcENRc0unw" />
  <title>Diversity-aware Channel Pruning for StyleGAN Compression</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NH1SJVRE8F"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NH1SJVRE8F');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <script
	type="text/javascript"
    async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML"
  ></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/jiwoogit">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://jiwoogit.github.io/DCP-GAN_site">
            DCP-GAN
          </a>
          <a class="navbar-item" href="https://jiwoogit.github.io/StyleID_site">
            StyleID
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">Diversity-aware Channel Pruning for StyleGAN Compression (CVPR 2024)</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jiwoogit.github.io">Jiwoo Chung,</a></span>
            <span class="author-block">
              Sangeek Hyun,</span>
            <span class="author-block">
              Sang-Heon Shim,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/jaepilheo">Jae-Pil Heo</a><sup>*</sup></span>
            </span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block">*: corresponding author</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Sungkyunkwan University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2312.09008.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.13548"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jiwoogit/DCP-GAN"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h4 class="title is-5">These results use only 30% of the original channel count.</h4>
        <img src="./static/images/teaser.png" alt="Teaser image">
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            StyleGAN has shown remarkable performance in unconditional image generation.
            However, its high computational cost poses a significant challenge for practical applications.
            Although recent efforts have been made to compress StyleGAN while preserving its performance, existing compressed models still lag behind the original model, particularly in terms of sample diversity.
          </p>
          <p>
            To overcome this, we propose a novel channel pruning method that leverages varying sensitivities of channels to latent vectors, which is a key factor in sample diversity.
            Specifically, by assessing channel importance based on their sensitivities to latent vector perturbations, our method enhances the diversity of samples in the compressed model.
            Since our method solely focuses on the channel pruning stage, it has complementary benefits with prior training schemes without additional training cost.
          </p>
          <p>
            Extensive experiments demonstrate that our method significantly enhances sample diversity across various datasets.
            Moreover, in terms of FID scores, our method not only surpasses state-of-the-art by a large margin but also achieves comparable scores with only half training iterations.
          </p>
          <p>
          </p>
          <p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
        <p>
         <b>(a) Intuitive illustration of our method.</b>
         We compare four channels (Ch. #1, 2, 3, 4) by evaluating their responses when we pass the same latent vector \(w\) and its perturbed counterpart \((w+\alpha d)\).
         By investigating the contribution of each channel to resulting image difference, we determine the sensitivity of channels to the latent perturbation.
         In this example, <font color="#8baada"><b>Ch. #4</b></font> is highly sensitive to the perturbation, while <font color="#fab187"><b>Ch. #1,</b></font> <font color="#ffd971"><b>2,</b></font> <font color="#c9c9c9"><b>3</b></font> exhibit low sensitivity.
         Consequently, in terms of preserving sample diversity, <font color="#8baada"><b>Ch. #4</b></font> is suitable for retaining.
        </p>
        </p>
          <b>(b) Our overall framework.</b>
          We aim to assess the contribution of each channel to the sample diversity by measuring its sensitivity to latent vector perturbation.
          In detail, 1) we sample a directional vector for the perturbation, 2) we compute the image-level difference caused by the latent vector perturbation, and 3) we calculate channel-wise gradient magnitudes induced by the difference image.
          The channel-wise sensitivity to the sample diversity is determined by its gradient magnitudes.
        </p>
        <img src="./static/images/main_method.png" alt="Overview for our method">
      </div>
    </div>
  </div>
</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <img src="./static/images/main_result.png" alt="Qualitative comparisons for the baselines">
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="columns is-centered">
      <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">FID graph in FFHQ-256</h2>
            <p>
              We visualize FID curve during training and validate that ours achieves previous SOTA FIDs only with 2\(\times\) fewer iterations.
            </p>
            <img src="./static/images/graphtwo.png" alt="FID graph during training stage">
            
          </div>
        </div>
        <!--/ Visual Effects. -->

        <!-- Matting. -->
        <div class="column">
          <h2 class="title is-3">Quantitative Comparisons</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                These FID score improvements demonstrate the superiority of the distribution-matching capability of the proposed method.
              </p>
              <img src="./static/images/main_table.png" alt="Loading">
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chung2024diversity,
  title={Diversity-aware Channel Pruning for StyleGAN Compression},
  author={Chung, Jiwoo and Hyun, Sangeek and Shim, Sang-Heon and Heo, Jae-Pil},
  journal={arXiv preprint arXiv:2403.13548},
  year={2024}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
